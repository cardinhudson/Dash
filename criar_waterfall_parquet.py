#!/usr/bin/env python3
"""
Script para criar arquivo parquet otimizado especificamente para o gr√°fico Waterfall
Mant√©m apenas as colunas essenciais e aplica sumariza√ß√£o quando poss√≠vel
"""

import pandas as pd
import os
import sys

def criar_waterfall_parquet():
    """Cria arquivo parquet otimizado para waterfall"""
    
    print("üåä === CRIANDO ARQUIVO WATERFALL OTIMIZADO ===")
    
    # Verificar se arquivo original existe
    arquivo_origem = os.path.join("KE5Z", "KE5Z.parquet")
    if not os.path.exists(arquivo_origem):
        print("‚ùå Erro: Arquivo KE5Z.parquet n√£o encontrado!")
        return False
    
    print(f"üìÇ Carregando dados de: {arquivo_origem}")
    
    try:
        # Carregar dados completos
        df_original = pd.read_parquet(arquivo_origem)
        print(f"üìä Dados originais: {len(df_original):,} registros, {len(df_original.columns)} colunas")
        
        # Definir colunas essenciais para o waterfall
        colunas_waterfall = [
            'Per√≠odo',      # OBRIGAT√ìRIA - Para sele√ß√£o de meses
            'Valor',        # OBRIGAT√ìRIA - Para c√°lculos
            'USI',          # Filtro principal + dimens√£o
            'Type 05',      # Dimens√£o de categoria
            'Type 06',      # Dimens√£o de categoria
            'Type 07',      # Dimens√£o de categoria
            'Fornecedor',   # Dimens√£o de categoria + filtro
            'Centro cst',   # Filtro
            'N¬∫ conta',     # Filtro
            'Fornec.',      # Filtro
            'Tipo'          # Filtro
        ]
        
        # Verificar quais colunas existem
        colunas_existentes = [col for col in colunas_waterfall if col in df_original.columns]
        colunas_faltantes = [col for col in colunas_waterfall if col not in df_original.columns]
        
        print(f"‚úÖ Colunas encontradas ({len(colunas_existentes)}): {colunas_existentes}")
        if colunas_faltantes:
            print(f"‚ö†Ô∏è Colunas n√£o encontradas ({len(colunas_faltantes)}): {colunas_faltantes}")
        
        # Filtrar apenas colunas essenciais
        df_waterfall = df_original[colunas_existentes].copy()
        
        print(f"üîÑ Dados filtrados: {len(df_waterfall):,} registros, {len(df_waterfall.columns)} colunas")
        
        # Aplicar otimiza√ß√µes de mem√≥ria
        print("‚ö° Aplicando otimiza√ß√µes de mem√≥ria...")
        
        # Converter strings categ√≥ricas para category
        for col in df_waterfall.columns:
            if df_waterfall[col].dtype == 'object':
                unique_ratio = df_waterfall[col].nunique(dropna=True) / max(1, len(df_waterfall))
                if unique_ratio < 0.5:  # Se menos de 50% s√£o valores √∫nicos
                    df_waterfall[col] = df_waterfall[col].astype('category')
                    print(f"  üìã {col}: convertido para category ({unique_ratio:.1%} √∫nicos)")
        
        # Otimizar tipos num√©ricos
        for col in df_waterfall.select_dtypes(include=['float64']).columns:
            df_waterfall[col] = pd.to_numeric(df_waterfall[col], downcast='float')
            print(f"  üìä {col}: otimizado para float32")
        
        for col in df_waterfall.select_dtypes(include=['int64']).columns:
            df_waterfall[col] = pd.to_numeric(df_waterfall[col], downcast='integer')
            print(f"  üî¢ {col}: otimizado para int32")
        
        # Remover registros com valores nulos nas colunas cr√≠ticas
        antes_limpeza = len(df_waterfall)
        df_waterfall = df_waterfall.dropna(subset=['Per√≠odo', 'Valor'])
        depois_limpeza = len(df_waterfall)
        
        if antes_limpeza != depois_limpeza:
            print(f"üßπ Removidos {antes_limpeza - depois_limpeza:,} registros com valores nulos em colunas cr√≠ticas")
        
        # Salvar arquivo otimizado
        pasta_destino = "KE5Z"
        os.makedirs(pasta_destino, exist_ok=True)
        
        arquivo_destino = os.path.join(pasta_destino, "KE5Z_waterfall.parquet")
        df_waterfall.to_parquet(arquivo_destino, index=False)
        
        # Calcular tamanhos
        tamanho_original = os.path.getsize(arquivo_origem) / (1024*1024)
        tamanho_waterfall = os.path.getsize(arquivo_destino) / (1024*1024)
        reducao = ((tamanho_original - tamanho_waterfall) / tamanho_original) * 100
        
        print(f"\n‚úÖ === ARQUIVO WATERFALL CRIADO COM SUCESSO ===")
        print(f"üìÅ Arquivo: {arquivo_destino}")
        print(f"üìä Registros: {len(df_waterfall):,}")
        print(f"üìã Colunas: {len(df_waterfall.columns)}")
        print(f"üíæ Tamanho original: {tamanho_original:.1f} MB")
        print(f"üíæ Tamanho otimizado: {tamanho_waterfall:.1f} MB")
        print(f"‚ö° Redu√ß√£o: {reducao:.1f}%")
        
        # Mostrar estat√≠sticas das colunas
        print(f"\nüìà ESTAT√çSTICAS DAS COLUNAS:")
        for col in df_waterfall.columns:
            if col in ['Per√≠odo', 'Valor']:
                valores_unicos = df_waterfall[col].nunique()
                print(f"  üîë {col}: {valores_unicos:,} valores √∫nicos")
            elif df_waterfall[col].dtype.name == 'category' or df_waterfall[col].dtype == 'object':
                valores_unicos = df_waterfall[col].nunique()
                print(f"  üìã {col}: {valores_unicos:,} categorias")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Erro ao criar arquivo waterfall: {str(e)}")
        return False

if __name__ == "__main__":
    sucesso = criar_waterfall_parquet()
    if sucesso:
        print("\nüéâ Processo conclu√≠do com sucesso!")
        sys.exit(0)
    else:
        print("\nüí• Processo falhou!")
        sys.exit(1)
